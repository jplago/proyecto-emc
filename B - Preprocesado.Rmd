En este notebook:
- Se generan data frames con los datos de las matrices de conectividad de todos los sujetos en cada grupo
- Se integran los datos fenotípicos 
- Se estandarizan los datos
- Se guardan las nuevas versiones de los datos

```{r}
library(mlr)
library(stringr)
library(caret)
```


```{r}
# Se cargan datos fenotípicos de train y test

df_train_KKI = read.csv('data/pheno_data_KKI_train.csv', stringsAsFactors = F)
df_train_Peking = read.csv('data/pheno_data_Peking_train.csv', stringsAsFactors = F)
df_test_KKI = read.csv('data/pheno_data_KKI_test.csv', stringsAsFactors = F)
df_test_Peking = read.csv('data/pheno_data_Peking_test.csv', stringsAsFactors = F)
```


```{r}
# Ejemplo de datos fenotípicos

df_train_Peking
```


```{r}
## Función que genera un único dataframe con los datos de las matrices de conectividad de todos los sujetos convertidas a vectores

N = 190

build_connectivity_dataframe = function(rutas){
  # Vector con nombre de columnas
  f = function(i,j){
    # Interesan solamente las que correspondan a entradas (i,j) con i<j ya que las matrices de conectividad son simétricas y con diagonal constante 1.
    out = ifelse(i>j, str_c(as.character(i), '_', as.character(j)), 'discard')
    return(out)
  }
  columns_names_vector = as.vector(outer(1:N, 1:N, FUN = f))
  
  FC_df = data.frame(matrix(vector(), nrow=length(rutas), ncol=N^2))
  colnames(FC_df) = columns_names_vector
  
  for (i in 1:length(rutas)){
      print(i)
      x = as.matrix(read.table(rutas[i]))
      FC_df[i,] = as.vector(x) 
  }
  
  return(FC_df[,colnames(FC_df) != 'discard'])
}
```

```{r}
# Función que agrega columnas con datos fenotípicos

pheno_columns = c("Age", "Verbal.IQ", "Performance.IQ", "Full4.IQ")

add_pheno_columns = function(df, mat_data, pheno_columns){
  return(cbind(df, mat_data[,pheno_columns]))
}
```

```{r}
# Función que estandariza los datos y elimina columnas con varianza cero.

standardise_data = function(X_train, X_test){
  stdParam = preProcess(X_train, method=c('center', 'scale', 'zv'))
  return(list(predict(stdParam, X_train), predict(stdParam, X_test)))
}
```


```{r}
# Preprocesado completo

full_preproc = function(df_train, df_test, rutas_FC_train, rutas_FC_test, pheno_columns, save_route_train, save_route_test){
  
  print(save_route_train)
  FC_train = build_connectivity_dataframe(rutas_FC_train)
  FC_test = build_connectivity_dataframe(rutas_FC_test)

  X_train = add_pheno_columns(FC_train, df_train, pheno_columns)
  X_test = add_pheno_columns(FC_test, df_test, pheno_columns)

  std_data = standardise_data(X_train, X_test)
  X_train = std_data[[1]]
  X_test = std_data[[2]] 
  
  data_train = cbind(X_train, df_train[,'DX_bin',drop=F])
  data_test = cbind(X_test, df_test[,'DX_bin',drop=F])
  
  write.csv(data_train, save_route_train, row.names = F)
  write.csv(data_test, save_route_test, row.names = F)
}


full_preproc(df_train_KKI, df_test_KKI, df_train_KKI$Ruta_FC_raj, df_test_KKI$Ruta_FC_raj, pheno_columns, 'data/data_raj_train_KKI_preproc.csv', 'data/data_raj_test_KKI_preproc.csv')

full_preproc(df_train_Peking, df_test_Peking, df_train_Peking$Ruta_FC_raj, df_test_Peking$Ruta_FC_raj, pheno_columns, 'data/data_raj_train_Peking_preproc.csv', 'data/data_raj_test_Peking_preproc.csv')
```

```{r}
# Dimensiones de los datos

data_train_Peking = read.csv('data/data_raj_train_Peking_preproc.csv')
data_train_KKI = read.csv('data/data_raj_train_KKI_preproc.csv')

cat('Dimensiones de los datos preprocesados\n')
cat('Peking:', dim(data_train_Peking), '\n')
cat('KKI:', dim(data_train_KKI))
```
